{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "749107b6",
   "metadata": {},
   "source": [
    "# Questão 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61477357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 31)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from numpy import genfromtxt\n",
    "bc_data = genfromtxt('breastcancer.csv', delimiter=',')\n",
    "bc_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68744284",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data_X = bc_data[:, :-1]\n",
    "bc_data_y = bc_data[:, [-1]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f045ced",
   "metadata": {},
   "source": [
    "#### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a4a3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracies(y_pred, y_val):\n",
    "    by_class_accuracies = []\n",
    "    accuracies = []\n",
    "\n",
    "\n",
    "    #print(y_pred,y_val)\n",
    "    #print('/n --------------')\n",
    "\n",
    "    if  y_val.shape[1] > 1:\n",
    "         y_val = np.argmax(y_val, axis=1)    \n",
    "\n",
    "    y_pred = y_pred.ravel()         \n",
    "    y_val = y_val.ravel().astype(int)  \n",
    "\n",
    "    classes = np.unique(y_val)\n",
    "    y_val = y_val.ravel()\n",
    "\n",
    "    for k in classes: \n",
    "        y_pred_k = y_pred[y_val == k]\n",
    "        y_val_k = y_val[y_val == k]\n",
    "        class_acc = np.mean(y_pred_k==y_val_k)\n",
    "        by_class_accuracies.append(class_acc)\n",
    "    #   print(y_pred_k,y_val_k)\n",
    "    \n",
    "    accuracy = np.mean(y_pred == y_val)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    return accuracies, by_class_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023f49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 fold cross validation:\n",
    "def k_fold_cross_validation(X, y, predicao, k=10):\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    general = []\n",
    "    by_class = []\n",
    "    fold_size = len(X) // k\n",
    "    \n",
    "    for i in range(k):\n",
    "\n",
    "        start = i * fold_size\n",
    "        end = (i + 1) * fold_size if i != k - 1 else len(X)  \n",
    "        val_indices = indices[start:end]\n",
    "        train_indices = np.concatenate((indices[:start], indices[end:]))\n",
    "\n",
    "        X_treino, y_treino = X[train_indices], y[train_indices]\n",
    "        X_val, y_val = X[val_indices], y[val_indices]\n",
    "\n",
    "        mean = X_treino.mean(axis=0)\n",
    "        std = X_treino.std(axis=0, ddof=1)\n",
    "\n",
    "        std[std == 0] = 1\n",
    "        X_treino_norm = (X_treino - mean) / std\n",
    "        X_val_norm = (X_val - mean) / std\n",
    "\n",
    "        y_pred = predicao(X_treino_norm, y_treino, X_val_norm)\n",
    "        \n",
    "        general_fold, by_class_fold = compute_accuracies(y_pred, y_val)\n",
    "        general.append(general_fold)\n",
    "        by_class.append(by_class_fold)\n",
    "        \n",
    "    by_class = np.mean(by_class, axis = 0)\n",
    "\n",
    "    return general, by_class\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e17ee5",
   "metadata": {},
   "source": [
    "## item a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7732fc",
   "metadata": {},
   "source": [
    "#### Regressão logística: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f25f8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def pesosLogistica(X, y, alfa, n_iters):\n",
    "    #X e um vetor de entradas com a primeira coluna somente com numeros 1's\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    w = np.zeros((n_features,1))\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        pred_linear = np.dot(X, w)\n",
    "        y_pred = sigmoid(pred_linear)\n",
    "        \n",
    "        erros = y - y_pred\n",
    "\n",
    "        w += (alfa/n_samples)*X.T.dot(erros)\n",
    "\n",
    "    return w\n",
    "\n",
    "def predicaoLogistica(X_treino, y_treino, X_teste):\n",
    "    w = pesosLogistica(X_treino,y_treino,0.1,1000)\n",
    "    probs = sigmoid(np.dot(X_teste, w))\n",
    "    return (probs >= 0.5).astype(int).ravel() # Regressao logistica binaria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122617bf",
   "metadata": {},
   "source": [
    "#### Análise do discriminante Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23c61b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinarGDA(X_treino, y_treino):\n",
    "    #y_treino = y_treino.ravel()\n",
    "    classes = np.unique(y_treino)\n",
    "    K = len(classes)\n",
    "    m, n = X_treino.shape\n",
    "\n",
    "    mu = np.zeros((K, n))\n",
    "    phi = np.zeros(K)\n",
    "    sigma = np.zeros((n, n))\n",
    "\n",
    "    for k in range(K):\n",
    "        X_k = X_treino[y_treino.ravel() == k]\n",
    "        mu[k] = X_k.mean(axis=0)\n",
    "        phi[k] = len(X_k) / m\n",
    "        sigma += (X_k - mu[k]).T @ (X_k - mu[k])\n",
    "\n",
    "    sigma /= m\n",
    "    sigma_inv = np.linalg.inv(sigma)\n",
    "\n",
    "    return mu, sigma_inv, phi\n",
    "\n",
    "def predicaoGDA(X_treino, y_treino, X_val):\n",
    "    mu, sigma_inv, phi = treinarGDA(X_treino, y_treino)\n",
    "    K = mu.shape[0]\n",
    "    preds = []\n",
    "\n",
    "    for x in X_val:\n",
    "        log_probs = []\n",
    "        for k in range(K):\n",
    "            delta = x - mu[k]\n",
    "            score = -0.5 * delta @ sigma_inv @ delta.T + np.log(phi[k])\n",
    "            log_probs.append(score)\n",
    "        preds.append(np.argmax(log_probs))\n",
    "\n",
    "\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e32cfe",
   "metadata": {},
   "source": [
    "#### Naive-Bayes Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446d1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def treinarNBG(X_treino, y_treino):\n",
    "    \n",
    "    #y_treino = y_treino.ravel()\n",
    "    classes = np.unique(y_treino)\n",
    "    n_classes = len(classes)\n",
    "    m, n = X_treino.shape\n",
    "\n",
    "    priors = np.zeros(n_classes)\n",
    "    means = np.zeros((n_classes,n))\n",
    "    variances = np.zeros((n_classes,n))\n",
    "\n",
    "    for idx, c in enumerate(classes):\n",
    "        X_c = X_treino[y_treino.ravel() == c]\n",
    "        priors[idx] = X_c.shape[0] / m\n",
    "        means[idx, :] = np.mean(X_c, axis = 0)\n",
    "        variances[idx, :] = np.var(X_c, axis = 0,ddof=1)  \n",
    "\n",
    "    return classes, priors, means, variances\n",
    "\n",
    "\n",
    "def previsaoNBG(X_treino, y_treino, X_val):\n",
    "    classes, priors, means, variances = treinarNBG(X_treino, y_treino)\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for x in X_val:\n",
    "        posteriors = []\n",
    "        for idx, c in enumerate(classes):\n",
    "            log_likelihood = -0.5 * np.sum(np.log(2 * np.pi * variances[idx] + 1e-9) + ((x - means[idx])**2) / (variances[idx] ))\n",
    "            posterior = np.log(priors[idx]) + log_likelihood\n",
    "            posteriors.append(posterior)\n",
    "\n",
    "        predictions.append(classes[np.argmax(posteriors)])\n",
    "\n",
    "    return np.array(predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ac144",
   "metadata": {},
   "source": [
    "## item b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7d1f82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_data_X1 = np.c_[np.ones(bc_data_X.shape[0]), bc_data_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe20a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média total para regressão logística:  0.9734615384615385\n",
      "Acurácia média por classe para regressão logística:  [0.97993971 0.9628805 ]\n"
     ]
    }
   ],
   "source": [
    "acc, class_acc = k_fold_cross_validation(bc_data_X1,bc_data_y, predicaoLogistica)\n",
    "print('Acurácia média total para regressão logística: ', np.mean(acc)) \n",
    "print('Acurácia média por classe para regressão logística: ', class_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca02b5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média total para GDA:  0.9617032967032966\n",
      "Acurácia média por classe para GDA:  [0.99772727 0.90331557]\n"
     ]
    }
   ],
   "source": [
    "acc, class_acc = k_fold_cross_validation(bc_data_X,bc_data_y, predicaoGDA)\n",
    "print('Acurácia média total para GDA: ', np.mean(acc)) \n",
    "print('Acurácia média por classe para GDA: ', class_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8158e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média total para NBG:  0.9333791208791208\n",
      "Acurácia média por classe para NBG:  [0.95579282 0.89243122]\n"
     ]
    }
   ],
   "source": [
    "acc, class_acc = k_fold_cross_validation(bc_data_X,bc_data_y, previsaoNBG)\n",
    "print('Acurácia média total para NBG: ', np.mean(acc)) \n",
    "print('Acurácia média por classe para NBG: ', class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab1a49",
   "metadata": {},
   "source": [
    "# Questão 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8ce93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle = genfromtxt('vehicle.csv', delimiter=',')\n",
    "vehicle_y = vehicle[:, [18]]\n",
    "vehicle_X = vehicle[:, :18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5fea40",
   "metadata": {},
   "source": [
    "#### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f723586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "vehicle_y_encoded = encoder.fit_transform(vehicle_y)\n",
    "vehicle_y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842c29f",
   "metadata": {},
   "source": [
    "## item a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d485cca6",
   "metadata": {},
   "source": [
    "#### Regressão Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bae4438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "def treinarsoftmax(X, y, lr=0.1, n_iters=1000):\n",
    "    \n",
    "    m, n = X.shape    \n",
    "    K = y.shape[1]  \n",
    "    W = np.zeros((n, K))        \n",
    "\n",
    "    for _ in range(n_iters):\n",
    "        logits = np.dot(X, W)         \n",
    "        probs = softmax(logits)       \n",
    "        W -= lr * (1 / m) * np.dot(X.T, (probs - y))\n",
    "\n",
    "    return W\n",
    "\n",
    "def predicaoSoftmax(X_train, y_train, X_test):\n",
    "    W = treinarsoftmax(X_train, y_train)\n",
    "    probs = softmax(np.dot(X_test, W))\n",
    "    return np.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3798203",
   "metadata": {},
   "source": [
    "## item b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8650253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_X1 = np.c_[np.ones(vehicle_X.shape[0]), vehicle_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "41f1cc38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média total para regressão softmax:  0.7526190476190476\n",
      "Acurácia média por classe para regressão softmax:  [0.91554418 0.55715866 0.56671841 0.97477472]\n"
     ]
    }
   ],
   "source": [
    "acc, class_acc = k_fold_cross_validation(vehicle_X1, vehicle_y_encoded, predicaoSoftmax)\n",
    "print('Acurácia média total para regressão softmax: ', np.mean(acc)) \n",
    "print('Acurácia média por classe para regressão softmax: ', class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "538e0150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média total para GDA:  0.7763492063492062\n",
      "Acurácia média por classe para GDA:  [0.95651148 0.6017922  0.60269186 0.94719833]\n"
     ]
    }
   ],
   "source": [
    "acc, class_acc = k_fold_cross_validation(vehicle_X, vehicle_y, predicaoGDA)\n",
    "print('Acurácia média total para GDA: ', np.mean(acc)) \n",
    "print('Acurácia média por classe para GDA: ', class_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93485af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média total para NBG:  0.4660317460317461\n",
      "Acurácia média por classe para NBG:  [0.17585686 0.42684504 0.40817517 0.88589583]\n"
     ]
    }
   ],
   "source": [
    "acc, class_acc = k_fold_cross_validation(vehicle_X, vehicle_y, previsaoNBG)\n",
    "print('Acurácia média total para NBG: ', np.mean(acc)) \n",
    "print('Acurácia média por classe para NBG: ', class_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99833fb2",
   "metadata": {},
   "source": [
    "## Considerações finais: \n",
    "\n",
    "Os modelos funcionam consideravelmente melhor para os casos de classificação binária da questão 1, a maior disparidade de acurácia se dá no modelo naive-bayes que performa muito pior no caso multiclasse da questão 2, oque, em tese, é coerente, mas pode ter sido alguma falha na implementação do modelo que não identifiquei. \n",
    "\n",
    "Outro ponto importante é que o modelo de regressão logística aplicado no item a) da questão 1 está um pouco duvidoso, devido a uma acurácia muito grande em varios folds. O modelo performa, em média 97-98% de acurácia e chega a ter, em várias iterações dos k-folds, precisão de 100%, o que, muito provavelmente, indica um erro na implementação que não consegui encontrar, visto que, comparando com a implementação de regressão logística e dos k-fold do scikit-learn a precisão média geral não costuma passar 95% para o mesmo dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
